## 垃圾清理

在KAP运行一段时间之后，有很多数据因为不再使用而变成了垃圾数据，这些数据占据着大量HDFS、HBase等资源，当积累到一定规模会对集群性能产生影响。
这些垃圾数据主要包括：

- Purge之后原Cube的数据
- Cube合并之后原Cube Segment的数据
- 任务中未被正常清理的临时文件
- 很久之前Cube构建的日志和任务历史

为了对这些垃圾数据进行清理，KAP提供了两个常用的工具。请特别注意，数据一经删除将彻底无法恢复！建议使用前进行元数据备份，并对目标资源进行谨慎核对。

### 清理元数据
第一个是元数据清理工具，该工具有一个delete参数，默认是false。只有当delete参数为true，工具才会真正对无效的元数据进行删除。该工具的执行方式如下：

```$KYLIN_HOME/bin/metastore.sh clean [--delete true]```
第一次执行该工具时建议省去delete参数，这样会只列出所有可以被清理的资源供用户核对，而并不实际进行删除操作。当用户确认无误后，再添加delete参数并执行命令，才会进行实际的删除操作。默认情况下，该工具会清理的资源列表如下：

- 2天前创建的已无效的Lookup表镜像、字典、Cube统计信息
- 30天前结束的Cube构建任务的步骤信息、步骤输出

### 清理存储器
第二个工具是存储器清理工具。顾名思义，就是对HBase和HDFS上的资源进行清理。同样的，该工具也有一个delete参数，默认是false。当且仅当delete参数的值是true，工具才会对存储器中的资源真正执行删除操作。该工具的执行方式如下：

```$KYLIN_HOME/bin/kylin.sh org.apache.kylin.storage.hbase.util.StorageCleanupJob [--delete true] [--force true]```
第一次执行该工具时建议省去delete参数，这样会只列出所有可以被清理的资源供用户核对，而并不实际进行删除操作。当用户确认无误后，再添加delete参数并执行命令，才会进行实际的删除操作。默认情况下，该工具会清理的资源列表如下：

- 创建时间在2天前，且已无效的HTable
- 在Cube构建时创建的但未被正常清理的的Hive中间表、HDFS临时文件

如果force参数为true，则删除所有Hive中间表